---
# Kubernetes Cluster with WireGuard Overlay Network
# Main deployment playbook

- name: Setup Common Prerequisites
  hosts: all
  become: true
  gather_facts: true

  pre_tasks:
    - name: Update apt cache (Debian/Ubuntu)
      ansible.builtin.apt:
        update_cache: true
        cache_valid_time: 3600
      when: ansible_os_family == "Debian" # Ubuntu is part of Debian family

    - name: Ensure required directories exist
      ansible.builtin.file:
        path: "{{ item }}"
        state: directory
        mode: "0755"
      loop: # Ensure these directories exist on all nodes
        - /opt/cni/bin
        - /etc/wireguard
        - /etc/kubernetes

  roles:
    - common
    - kubernetes

- name: Generate WireGuard Keys
  hosts: all
  become: true
  gather_facts: false
  tags: wireguard

  tasks:
    - name: Install WireGuard
      ansible.builtin.package:
        name:
          - wireguard
          - wireguard-tools
        state: present

    - name: Generate WireGuard private key
      ansible.builtin.command: wg genkey
      register: private_key
      changed_when: false
      no_log: true

    - name: Generate WireGuard public key
      ansible.builtin.shell:
        cmd: set -o pipefail && echo "{{ private_key.stdout }}" | wg pubkey
      args:
        executable: /bin/bash
      register: public_key
      changed_when: false
      no_log: true

    - name: Store keys in facts
      ansible.builtin.set_fact:
        wireguard_private_key: "{{ private_key.stdout }}"
        wireguard_public_key: "{{ public_key.stdout }}"
      no_log: true

- name: Configure WireGuard
  hosts: all
  become: true
  gather_facts: false
  tags: wireguard

  tasks:
    # Incremental peer configuration for control plane
    - name: Fetch existing WireGuard peer state on control plane
      ansible.builtin.include_tasks: roles/wireguard/tasks/fetch_existing_peers.yml
      when: inventory_hostname in groups['control_plane']

    - name: Merge peer configurations on control plane
      ansible.builtin.include_tasks: roles/wireguard/tasks/merge_peer_config.yml
      when: inventory_hostname in groups['control_plane']

    # Dry-run mode: Generate config to temp location and show diff
    - name: Generate WireGuard configuration preview (dry-run mode)
      ansible.builtin.include_tasks: roles/wireguard/tasks/dry_run_config.yml
      when: wireguard_dry_run | default(false) | bool

    # Normal mode: Apply configuration
    - name: Create WireGuard configuration
      ansible.builtin.template:
        src: "roles/wireguard/templates/{{ wireguard_interface }}.conf.j2"
        dest: "/etc/wireguard/{{ wireguard_interface }}.conf"
        mode: "0600"
        backup: true
      notify: Restart WireGuard
      when: not (wireguard_dry_run | default(false) | bool)

    - name: Enable and start WireGuard service
      ansible.builtin.systemd:
        name: "wg-quick@{{ wireguard_interface }}"
        enabled: true
        state: started
      when: not (wireguard_dry_run | default(false) | bool)

    - name: Install and configure UFW on all nodes
      ansible.builtin.package:
        name: ufw
        state: present

    - name: Configure UFW for control plane
      when: inventory_hostname in groups['control_plane']

      block:
        - name: Allow SSH access
          community.general.ufw:
            rule: allow
            port: "22"
            proto: tcp
            comment: "SSH access"

        - name: Allow Kubernetes API server
          community.general.ufw:
            rule: allow
            port: "6443"
            proto: tcp
            comment: "Kubernetes API server"

        - name: Allow etcd server client API
          community.general.ufw:
            rule: allow
            port: "2379:2380"
            proto: tcp
            comment: "etcd server client API"

        - name: Allow kubelet API
          community.general.ufw:
            rule: allow
            port: "10250"
            proto: tcp
            comment: "Kubernetes kubelet"

        - name: Allow kube-scheduler
          community.general.ufw:
            rule: allow
            port: "10259"
            proto: tcp
            comment: "kube-scheduler"

        - name: Allow kube-controller-manager
          community.general.ufw:
            rule: allow
            port: "10257"
            proto: tcp
            comment: "kube-controller-manager"

        - name: Allow WireGuard UDP port
          community.general.ufw:
            rule: allow
            port: "{{ wireguard_port }}"
            proto: udp
            comment: "WireGuard VPN"

        - name: Allow WireGuard interface traffic
          community.general.ufw:
            rule: allow
            direction: in
            interface: "{{ wireguard_interface }}"
            comment: "WireGuard interface input"

        - name: Allow WireGuard interface output
          community.general.ufw:
            rule: allow
            direction: out
            interface: "{{ wireguard_interface }}"
            comment: "WireGuard interface output"

        - name: Enable UFW firewall
          community.general.ufw:
            state: enabled
            policy: deny
            direction: incoming
    - name: Configure UFW for worker nodes
      when: inventory_hostname in groups['workers']

      block:
        - name: Allow SSH access
          community.general.ufw:
            rule: allow
            port: "22"
            proto: tcp
            comment: "SSH access"

        - name: Allow kubelet API
          community.general.ufw:
            rule: allow
            port: "10250"
            proto: tcp
            comment: "Kubernetes kubelet"

        - name: Allow NodePort services
          community.general.ufw:
            rule: allow
            port: "30000:32767"
            proto: tcp
            comment: "Kubernetes NodePort services"

        - name: Allow WireGuard interface input
          community.general.ufw:
            rule: allow
            direction: in
            interface: "{{ wireguard_interface }}"
            comment: "WireGuard interface input"

        - name: Allow WireGuard interface output
          community.general.ufw:
            rule: allow
            direction: out
            interface: "{{ wireguard_interface }}"
            comment: "WireGuard interface output"

        - name: Enable UFW firewall
          community.general.ufw:
            state: enabled
            policy: deny
            direction: incoming

    # Validate WireGuard peer configuration
    - name: Validate WireGuard peer configuration on control plane
      ansible.builtin.include_tasks: roles/wireguard/tasks/validate_peers.yml
      when:
        - inventory_hostname in groups['control_plane']
        - not (wireguard_dry_run | default(false) | bool)

  handlers:
    - name: Restart WireGuard
      ansible.builtin.systemd:
        name: "wg-quick@{{ wireguard_interface }}"
        state: restarted

- name: Initialize Control Plane
  hosts: control_plane
  become: true
  gather_facts: false

  roles:
    - control_plane

- name: Join Worker Nodes
  hosts: workers
  become: true
  gather_facts: false

  roles:
    - worker

- name: Prepare CNI Environment
  hosts: workers
  become: true
  gather_facts: false

  tasks:
    - name: Remove old CNI bridge interfaces that might conflict
      ansible.builtin.shell: |
        for bridge in cni0 docker0 flannel.1; do
          if ip link show $bridge >/dev/null 2>&1; then
            echo "Removing bridge: $bridge"
            ip link delete $bridge
          fi
        done
      register: bridge_cleanup_site
      changed_when: "'Removing bridge:' in bridge_cleanup_site.stdout"
      failed_when: false

    - name: Stop kubelet before CNI deployment
      ansible.builtin.systemd:
        name: kubelet
        state: stopped
      failed_when: false

- name: Deploy CNI
  hosts: control_plane
  become: true
  gather_facts: false

  roles:
    - cni

- name: Restart workers after CNI deployment
  hosts: workers
  become: true
  gather_facts: false

  tasks:
    - name: Restart kubelet on worker nodes after CNI deployment
      ansible.builtin.systemd:
        name: kubelet
        state: restarted
        enabled: true

    - name: Verify kubelet is running
      ansible.builtin.command: systemctl status kubelet
      register: kubelet_status
      changed_when: false

    - name: Show kubelet status
      ansible.builtin.debug:
        msg: "{{ kubelet_status.stdout_lines | default('Kubelet status unavailable') }}"
      when: kubelet_status is defined

- name: Verify CNI Deployment
  hosts: control_plane
  become: true
  gather_facts: false

  tasks:
    - name: Include CNI verification tasks
      ansible.builtin.include_tasks: roles/cni/tasks/verify_cni.yml
- name: Verify Deployment
  hosts: control_plane
  become: true
  gather_facts: false

  tasks:
    - name: Verify node status
      ansible.builtin.command: kubectl get nodes -o wide
      register: node_status
      become: true
      become_user: "{{ ansible_user }}"
      changed_when: false

    - name: Display cluster status
      ansible.builtin.debug:
        msg: "{{ node_status.stdout_lines }}"
